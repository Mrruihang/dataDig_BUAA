## 任务2：图像异常检测

### 2.0 问题的形式化描述
- 数据集 `Image_Anomaly_Detection` 包含两个工业视觉类别：`hazelnut/` 和 `zipper/`。  
  - 每个类别的训练集包含 **200 张正常图像**（`train/good/`）和 **50 张异常图像**（`train/bad/`）。  
  - 测试集 `test/` 混合包含正常与异常样本，具体标签由 `image_anomaly_labels.json` 提供（字段 `label ∈ {good, bad}`）。
- 我们将问题建模为 **无监督异常检测**：
  - 仅使用训练集中标记为 `good` 的图像学习“正常模式”的表示；
  - 在测试阶段，根据图像与“正常模式”的距离或置信度，判断该图像是否为异常。
- 形式化地，记单张图像为张量 $I \in \mathbb{R}^{H\times W\times C}$，经过特征提取函数 $\phi(\cdot)$得到向量特征 $x = \phi(I) \in \mathbb{R}^d$。  
  我们在仅由正常样本组成的特征集合 $\{x_i^{(normal)}\}$ 上训练一类模型 $g(\cdot)$，使其学习到正常数据的高密度区域；对任意测试样本 \(x\)，根据得分 $s = g(x)$与阈值的比较，给出“正常 / 异常”的判决。

### 2.1 如何处理图像特征
- **统一预处理**：
  - 使用 `PIL` 读取图像，转为灰度图（`convert("L")`），将尺寸统一缩放到 `64×64` 像素；
  - 像素值缩放到 $[0,1]$区间后按行展开，得到一个长度为 $64\times64 = 4096$ 的向量作为图像特征：  
    $x = \text{vec}\left(\frac{I_{gray}}{255}\right) \in \mathbb{R}^{4096}. $
- **标准化**：
  - 在所有训练集正常样本特征上拟合 `StandardScaler`，对每一维做零均值、单位方差的标准化；
  - 这样可以避免单个像素通道尺度差异过大，提升核方法（如 SVM）的效果。
- **降维可视化**：
  - 在评估阶段，使用 `PCA` 将测试特征从 4096 维降到 2 维，用于可视化正常与异常样本在特征空间中的分布差异。

### 2.2 异常检测模型与设计思想
- **模型选择：One-Class SVM**  
  - 使用 `sklearn.svm.OneClassSVM` 作为核心异常检测器，仅在训练集中 `train/good/` 的样本上拟合模型：  
    - 核函数：`RBF`（径向基核），用于刻画非线性决策边界；  
    - `gamma='scale'`：由数据自动确定核宽度；  
    - `nu=0.1`：表示先验上约 **10% 样本可以视作异常**，控制模型的“紧/松”程度。
  - 训练目标是在高维特征空间中学习一个包围正常样本的超球体 / 超曲面，使正常数据被判为 +1（inlier），异常数据落在外部被判为 -1（outlier）。
- **设计思路**：
  - 由于任务本质是“异常检测”，更关注“从正常模式偏离”的程度，而不仅仅是区分 hazelnut/zipper 这两大类，因此选择 **基于正常样本的一类学习（One-Class）** 更符合问题设定；
  - 图像数量相对有限（每类数百张），而高分辨率卷积网络训练代价较高，故采用 **简单的灰度缩放 + 展平特征**，用核方法捕捉非线性边界，是在算力和精度之间的折中;
  - 将 hazelnut 和 zipper 两类的正常样本合并建模，有利于学习更“泛化”的正常模式，提高对不同类别异常的检测能力。
- **实现脚本**：`python "anomaly detection/task2_image_anomaly.py"` 完成：
  - 训练集中 `hazelnut/train/good/` 与 `zipper/train/good/` 的特征加载与标准化；
  - 基于正常样本拟合 One-Class SVM 模型；
  - 使用 `image_anomaly_labels.json` 对测试集图像赋予 `good/bad` 标签并映射为 {1, -1} 进行评估；
  - 输出混淆矩阵、分类报告、ROC-AUC 并生成多种可视化结果。

### 2.3 评估与可视化结果
运行脚本后，在控制台得到如下关键数值指标（示例一次运行结果）：

- **分类指标（把 anomaly 视作“正类”进行解读）**：  
  - **Accuracy** ≈ 0.70：整体有近 70% 的测试样本被正确识别；  
  - **normal（正常）类**：召回率约 0.93，说明大部分正常样本能被正确识别为正常；  
  - **anomaly（异常）类**：召回率较低（约 0.13），但精度中等（约 0.44），说明模型更偏“保守”，宁可把可疑样本当成正常，也不容易误报；  
  - **ROC-AUC（异常 vs 正常）** ≈ 0.62：在无监督设定和简单特征前提下，模型对异常程度的排序能力仍有提升空间。

为便于直观理解模型表现，脚本在 `anomaly detection/figures/` 目录下生成了三张可视化图片：

- **`task2_roc_curve.png`：ROC 曲线**  
  - 横轴为 **False Positive Rate**（误报率），纵轴为 **True Positive Rate**（召回率），曲线越靠近左上角表示异常检测能力越强；  
  - 图中同时绘制了随机分类器的对角线作为参照，通过曲线与对角线的偏离程度，直观展示 One-Class SVM 的优势。

- **`task2_confusion_matrix.png`：混淆矩阵热力图**  
  - 将“真实正常 / 异常”与“预测正常 / 异常”的组合以 2×2 矩阵形式展示，并在格子中标注具体样本数；  
  - 可以一眼看出模型对正常样本的识别率较高，而对异常样本存在一定漏检，是后续优化（如采用更强特征或调节 `nu`、`gamma` 参数）的重要依据。

- **`task2_pca_test_features.png`：测试特征的 PCA 投影**  
  - 使用 `PCA` 将 4096 维特征降到 2 维，在平面上画出测试集中正常样本（蓝色点）和异常样本（红色叉号）；  
  - 若异常样本在投影空间中明显偏离正常簇，说明特征在一定程度上区分了正常与异常模式；若两者混杂，则提示需要引入更具表达力的图像特征（如 CNN 特征）或更复杂的异常检测模型。

总体而言，当前方案通过 **简单的灰度缩放特征 + One-Class SVM**，在无监督设置下实现了对图像异常的基础检测与可视化分析，为后续引入更强特征（HOG / 预训练 CNN）或更复杂方法（深度自编码器、VAE、Patch-based 检测等）提供了基线参考。

